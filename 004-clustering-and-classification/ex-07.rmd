# Discrimination and classification

Load the datasets,

```{r, message=FALSE}
load("_data/iris.train.rdata")
load("_data/iris.test.rdata")
source("_functions/CV.class.R")
```

Load the packages,

```{r, message=FALSE, warning=FALSE}
library(MASS)
```

## Iris Dataset

- a) Consider the famous iris data set `iris.train.rdata` as introduced in the lectures.
Reproduce the pairs plot for the four sepal and petal variables as given in the lectures.
Which variable appears to be discriminating the species best? And which is worst?

<div class="ans">

```{r, echo=FALSE}
pairs(iris.train[,-5], col = iris.train[,"Species"], pch = 20, cex = 2)
```

The two classes are best separated from the point of view of Petal.Length. The Sepal.Width looks like the worst discriminator.

</div>

- b) Explain the difference between “discrimination” and “classification”.

<div class="ans">

Discrimination corresponds to the model fitting process in statistical inference. We seek good variables for discriminating classes. Classification corresponds to the actual prediction of new samples, that is, to allocate new samples to classes using the presumably best "classifier"-model estimated from the training data.

</div>

- c) Explain what is meant by the assumption “We assume apriori that versicolor and virginica are equally likely”.

<div class="ans">

This means that both species are equally probable if you sample a random plant from the population.

</div>

- d) Fit an LDA model to the iris data using Sepal.Length as the predictor. Assume equal prior probabilities for both species. Use the `print()`-function on you fitted model. What are the sample means of each species for this predictor variable?

<div class="ans">

```{r}
mod1.lda <- lda(Species ~ Sepal.Length, data = iris.train, prior = c(0.5, 0.5))
mod1.lda
```

The means are reported in the print output as `Group means`.

</div>


- e) Source in the `CV.class.R` file (open the fil in the script window and press the "Source" button to the upper right). Look at the `CV.class.examples.R`-file for reference. Perform a Leave-One-Out Cross-Validation of the model you fitted in the previous exercise. Report the confusion matrix, the accuracy and the cross-validated error rate.

<div class="ans">

```{r, message=FALSE, warning=FALSE}
cvres1 <- CV.class(mod1.lda, data = iris.train)
```

The confusion matrix is given in the first part of the output. 32 out of 40 versicolor are correctly classified, whereas 29 out of 40 virginica are correct. In total 61 out of 80 are correctly classified giving an accuracy of 0.7625 as reported. The APER is 1-accuracy, hence APER=1-0.7625 = 0.2375. We typically seek classifiers that minimize the classification error rate.

</div>


- f) Use the scheme from exercises d. and e. to identify a good classifier for iris species. You may use either `lda` or `qda` and you may use one or several predictors. Report the cross-validated error for you "best choice".

<div class="ans">

Through some trial and error, and by looking at the pairs-plot from exercise a, my personal choice is the following model:


```{r}
mymod <- qda(Species ~ Petal.Length + Petal.Width, data = iris.train, prior = c(0.5, 0.5))
cvres2 <- CV.class(mymod, data = iris.train)
```

This has an accuracy of 0.95 and, hence, an error of 0.05.

</div>

- g) What is the model assumption difference between an LDA and a QDA model?

<div class="ans">

In LDA we assume equal variance structure for all classes, whereas in QDA we assume different
variance structures for all classes.

</div>

- h) Use the model of your choice to predict the samples in `iris.test.rdata`. Use the `confusion()`-function in the mixlm-library to evaluate the performance of your classifier.

<div class="ans">

```{r}
pred <- predict(mymod, newdata = iris.test)
confusion(iris.test$Species, pred$class)
```

The model I found in f. gave a perfect classification, accuracy=1.0 and error=0.0.

</div>

<!--
## Logistic regression

- a. We will consider the Species variable of the `iris.train.rdata` set as a binary response variable in these exercises. You may use the `Species` variable directly as response in the models. R will recode "versicolor" as 0 and "virginica" as 1. Hence, we will model the probability of a plant being "virginica" as a function of the predictor variable(s). Fit a logist regression model for Species using Petal.Length as predictor. Report the estimated coefficients of the linear predictor. Is the Petal.Length variable a significant predictor for the probability of "virginica" at 5% test level? What is the AIC-value?

<div class="ans">

```{r}
mod.glm1 <- glm(Species ~ Petal.Length, family = binomial, data = iris.train)
summary(mod.glm1)
```

The `Petal.length` is according to the Wald test significant at all test levels larger than `r round(summary(mod.glm1)$coef[2, 4], 5)`.

</div>


- b. What is the estimated probability of a plant having `Petal.Length` equal to 5 to be a "virginica"?

<div class="ans">

```{r}
predict(mod.glm1, new = list(Petal.Length = 5), type = "response")
```

</div>

- c. Compute the AIC also for models with each of the other three variables as sole predictors.
Which model is preferable from the AIC point of view?

<div class="ans">

```{r}
mod.glm2 <- glm(Species ~ Petal.Width, family = binomial, data = iris.train)
mod.glm3 <- glm(Species ~ Sepal.Width, family = binomial, data = iris.train)
mod.glm4 <- glm(Species ~ Sepal.Length, family = binomial, data = iris.train)
AIC(mod.glm1)
AIC(mod.glm2)
AIC(mod.glm3)
AIC(mod.glm4)
```

The `Petal.Length` variable gives the smallest AIC when used as predictor. It is marginally better than `Petal.Width` as prdictor.

</div>

- d. (Optional) Try to construct a plot like the plot on slide 9 from lesson 9 with `Petal.Length` as predictor.
You may need to make a variable `y` by `y <- ifelse(iris.train$Species=="virginica",1,0)` first.
You may also check out the code for slide 9 from the `Generalized1.rmd` file available on Fronter for more hints.

<div class="ans">

```{r}
y <- ifelse(iris.train$Species == "virginica",1,0)
x <- seq(2,8, by = 0.1)
ypred <- predict(mod.glm1, list(Petal.Length = x), type = "response")
plot(iris.train$Petal.Length, y, ylab = "Proportion virginica", xlab = "Petal.Length")
lines(x,ypred,col = "red")
```

</div>

- e. Use a logistic model of your choice (perhaps the same predictors as you used in your best choice classifier of Ex-1) to estimate the posterior probabilities of "virginica" for the samples of the `iris.test.Rdata` set. Allocate the samples to the most probable species class and use the `confusion()` function to evaluate the classification performance. (Hint: The posterior probabilies, say you name then `postprob`, should be classified into a factor variable by
    
    ```{r, eval=FALSE}
    predicted <- factor(ifelse(postprob > 0.5,"virginica","versicolor"))
    ```

<div class="ans">

```{r}
mymod2 <- glm(Species ~ Petal.Length + Petal.Width, family = binomial, data = iris.train)
postprob <- predict(mymod2, new = iris.test, type = "response")
predicted <- factor(ifelse(postprob > 0.5,"virginica","versicolor"))
confusion(iris.test$Species, predicted)
```

With my chosen model I got one mis-classification and an error rate of 0.05.

</div>
-->
